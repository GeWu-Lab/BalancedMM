# Balanced Multimodal Learning
A curated list of balanced multimodal learning methods.


# Table of contents
- [Balanced Multimodal Learning](#balanced-multimodal-learning)
- [Table of contents](#table-of-contents)
  - [GeWu-Lab paper](#gewu-lab-paper)
  - [Other balanced multimodal learning methods](#other-balanced-multimodal-learning-methods)



## GeWu-Lab paper
**[CVPR-2022]**
<br>
[Balanced Multimodal Learning via On-the-fly Gradient Modulation](https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Balanced_Multimodal_Learning_via_On-the-Fly_Gradient_Modulation_CVPR_2022_paper.pdf) 
<br>
**[Code](https://github.com/GeWu-Lab/OGM-GE_CVPR2022)**

**[ICASSP-2023]**
<br>
[MMCosine: Multi-Modal Cosine Loss Towards Balanced Audio-Visual Fine-Grained Learning](https://arxiv.org/abs/2303.05338) 
<br>
**[Code](https://github.com/GeWu-Lab/MMCosine_ICASSP23)**

**[ICLR-2024]**
<br>
[Quantifying and Enhancing Multi-modal Robustness with Modality Preference](https://arxiv.org/abs/2402.06244) 
<br>
**[Code](https://github.com/GeWu-Lab/Certifiable-Robust-Multi-modal-Training)**

**[CVPR-2024]**
<br>
[Enhancing Multimodal Cooperation via Sample-level Modality Valuation](https://arxiv.org/abs/2309.06255) 
<br>
**[Code](https://github.com/GeWu-Lab/Valuate-and-Enhance-Multimodal-Cooperation)**

**[ICML-2024]**
<br>
[MMPareto: Boosting Multimodal Learning with Innocent Unimodal Assistance](https://arxiv.org/abs/2405.17730) 
<br>
**[Code](https://github.com/GeWu-Lab/MMPareto_ICML2024)**


**[ECCV-2024]**
<br>
[Diagnosing and Re-learning for Balanced Multimodal Learning](#) 
<br>
**[Code](https://github.com/GeWu-Lab/Diagnosing_Relearning_ECCV2024)**


## Other balanced multimodal learning methods

- [What Makes Training Multi-Modal Classification Networks Hard?](https://arxiv.org/abs/1905.12681) [CVPR 2020]
- [Learning to Balance the Learning Rates between Various Modalities via Adaptive Tracking Factor](https://ieeexplore.ieee.org/document/9503315) [IEEE Signal Processing Letters  2021]
- [Audiovisual SlowFast Networks for Video Recognition](https://arxiv.org/abs/2001.08740) [arXiv 2020]
- [Joint Audio-Visual Deepfake Detection](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhou_Joint_Audio-Visual_Deepfake_Detection_ICCV_2021_paper.pdf) [ICCV 2021]
- [MCL: A Contrastive Learning Method for Multimodal Data Fusion in Violence Detection](https://ieeexplore.ieee.org/document/9976192) [IEEE Signal Processing Letters 2022]
- [On Uni-Modal Feature Learning in Supervised Multi-Modal Learning](https://proceedings.mlr.press/v202/du23e/du23e.pdf) [ICML 2023]
- [Multimodal Pre-Training with Self-Distillation for Product Understanding in E-Commerce](https://dl.acm.org/doi/10.1145/3539597.3570423) [WSDM 2023]
- [PMR: Prototypical Modal Rebalance for Multimodal Learning](https://openaccess.thecvf.com/content/CVPR2023/papers/Fan_PMR_Prototypical_Modal_Rebalance_for_Multimodal_Learning_CVPR_2023_paper.pdf) [CVPR 2023]
- [Graph Interactive Network with Adaptive Gradient for Multi-Modal Rumor Detection](https://dl.acm.org/doi/abs/10.1145/3591106.3592250) [ICMR 2023]
- [Multimodal Imbalance-Aware Gradient Modulation for Weakly-supervised Audio-Visual Video Parsing](https://arxiv.org/abs/2307.02041) [IEEE Transactions on Circuits and Systems for Video Technology 2023]
- [Multimodal Temporal Attention in Sentiment Analysis](https://dl.acm.org/doi/10.1145/3551876.3554811) [MuSe 2023]
- [Utilizing Greedy Nature for Multimodal Conditional Image Synthesis in Transformers](https://ieeexplore.ieee.org/document/10184483) [TMM 2023]
- [Variational Probabilistic Fusion Network for RGB-T Semantic Segmentation](https://arxiv.org/abs/2307.08536) [arXiv 2023]
- [Characterizing and Overcoming the Greedy Nature of Learning in Multi-modal Deep Neural Networks](https://proceedings.mlr.press/v162/wu22d/wu22d.pdf) [ICML 2022]
- [Adaptive Mask Co-Optimization for Modal Dependence in Multimodal Learning](https://ieeexplore.ieee.org/document/10096641) [ICASSP 2024]

